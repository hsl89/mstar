args:
- --nnodes=111
- --nproc_per_node=8
- --max_restarts=0
- pretrain_main.py
- lightning/plugins/environment=torch_elastic #necessary for elastic controller
- run_name=111node_auto_20B_shard24
- trainer.default_root_dir=/mnt_out/colehawk/tmp/
- model.ckpt_path="auto"
- optimization.optimizer.lr=0.0001
- optimization/scheduler=linear
- max_steps=100000
- model=20B
- deepspeed_path=config/deepspeed/bf16_zero2d_shard24.json
- lightning.callbacks.checkpoint.every_n_train_steps=1000
- trainer.limit_val_batches=10
- optimization.micro_batch_size=2
command: ["python3","-m","torch.distributed.run"]
image: 747303060528.dkr.ecr.us-east-1.amazonaws.com/mstar-eks:colehawk-restart-01-01
name: colehawk-20b-36n-s24
node_type: p4de.24xlarge
dag_type: "elastic_job_dag" # elastic job dag type
node_num: 111
min_replica: 111 #as for now keep the min_replica, max_replica, updated_replica as same
max_replica: 111
updated_replica: 111
max_dag_triggers: 3 # this parameter will trigger the restart of the dag if the launch job failed for some reason
