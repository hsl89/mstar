args:
- pretrain_main.py
- run_name=test_lr_20b
- trainer.max_steps=2000000
- optimizer.base_learning_rate=0.0001
- data=t5_prod_drop_2
- model=1_9B
- model.num_layers=2
- model.num_decoder_layers=2
- model.positional_embedding=alibi
- deepspeed_path=config/deepspeed/bf16_stage2.json
- trainer.precision=bf16 
- trainer.limit_val_batches=50
- trainer.val_check_interval=2000
- callback.save_every_n_train_steps=2000
- trainer.num_sanity_val_steps=0
- optimizer.lr_scheduler_type=hotfix_inverse_square_root
- trainer.num_nodes=2
- optimizer.micro_batch_size=1
- optimizer.total_batch_size=16
command:
- /usr/bin/python3
image: 747303060528.dkr.ecr.us-east-1.amazonaws.com/mstar-eks:colehawk-bedrock_new
name: chawk-bdrk-20B-p4
node_num: 2
node_type: p4d.24xlarge
