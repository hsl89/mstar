low_int: 0
high_int: 1000

tokenizer:
    _target_: mstar.AutoTokenizer.from_pretrained
    pretrained_model_name_or_path: "t5-base"
    max_tokenization_length: 10000

#test batches for concatenation
batches:
    batch_1:
        input_ids:
            _target_: numpy.random.randint
            low: ${....low_int}
            high: ${....high_int}
            size: [2,9]
        labels:
            _target_: numpy.random.randint
            low: ${....low_int}
            high: ${....high_int}
            size: [2,11]

    batch_2:
        input_ids:
            _target_: numpy.random.randint
            low: ${....low_int}
            high: ${....high_int}
            size: [1,17]
        labels:
            _target_: numpy.random.randint
            low: ${....low_int}
            high: ${....high_int}
            size: [1,3]
    
    batch_3:
        input_ids:
            _target_: numpy.random.randint
            low: ${....low_int}
            high: ${....high_int}
            size: [1,18]
        labels:
            _target_: numpy.random.randint
            low: ${....low_int}
            high: ${....high_int}
            size: [1,5]

expected_sizes:
    input_ids: [4,18]
    labels: [4,11]
