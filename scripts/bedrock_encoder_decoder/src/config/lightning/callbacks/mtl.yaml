checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    every_n_train_steps: 5000
    save_top_k: 100
    monitor: "labeled_val_loss"
    mode: "min"
    filename: "{epoch}-{step}-{labeled_val_loss:.2f}"
    save_last: True
    dirpath: null

lr_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "step"
        
#automatically stop job on nan
early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "labeled_val_loss"  # monitor this logged value
    mode: "min"
    patience: 100  # don't actually stop on train 
    strict: True  # monitored value must exist
    check_finite: True  # forces monitored value to be finite
    verbose: True

progress_bar:
    _target_: pytorch_lightning.callbacks.TQDMProgressBar
    refresh_rate: 10

