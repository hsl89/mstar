name: "RLFH-t5"
node_type: "p3dn.24xlarge"
node_num: 8
image: 747303060528.dkr.ecr.us-west-2.amazonaws.com/mstar-eks:kaixianl-rlfh-p3
command: ["/usr/bin/python3", 
          "scripts/rlfh/train.py",
          "-cn=config_tldr",
          "training.default_root_dir=/mnt_out/kaixianl/logs/${now:%Y-%m-%d}/${now:%H-%M-%S}",
          "hydra.run.dir=/mnt_out/kaixianl/logs/${now:%Y-%m-%d}/${now:%H-%M-%S}",
          "training.max_steps=10000000",
          "training.max_epochs=10",
          "training.limit_val_batches=1.0",
          "training.val_check_interval=1.0",
          "training.num_nodes=8",
          "training.gpus=-1",
          "datamodule.train_data_path=/mnt/kaixianl/tldr-openai-filtered/train.jsonl",
          "datamodule.test_data_path=/mnt/kaixianl/tldr-openai-filtered/test.jsonl",
          "datamodule.valid_data_path=/mnt/kaixianl/tldr-openai-filtered/valid.jsonl",
          "datamodule.train_hf_data_path=/mnt/kaixianl/summarize-from-feedback/comparisons/",
          "EKSArgs.experiment_name=kaixianl-RLFH",
          "EKSArgs.run_name=v2-sftp-t5-3b",
          "model.OptimizerArgs.seed=1",
          "model.OptimizerArgs.learning_rate=1e-5",
          "model.OptimizerArgs.loss_beta=0",
          "model.model_type=t5-3b",
          "model.tokenizer_type=t5-3b",
          "datamodule.batch_size=2",
          "datamodule.num_workers=0",
          ]
args: [
]