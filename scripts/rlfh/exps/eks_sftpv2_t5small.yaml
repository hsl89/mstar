name: "RLFH-60M-t5small"
node_type: "p3dn.24xlarge"
node_num: 2
image: 747303060528.dkr.ecr.us-west-2.amazonaws.com/mstar-eks:kaixianl-rlfh-p3
command: ["/usr/bin/python3", 
          "scripts/rlfh/train.py",
          "-cn=config_tldr_aligned",
          "training.default_root_dir=/mnt_out/kaixianl/logs/${now:%Y-%m-%d}/${now:%H-%M-%S}",
          "hydra.run.dir=/mnt_out/kaixianl/logs/${now:%Y-%m-%d}/${now:%H-%M-%S}",
          "training.max_steps=10000000",
          "training.max_epochs=10",
          "training.limit_val_batches=1.0",
          "training.val_check_interval=1.0",
          "training.num_nodes=2",
          "training.gpus=-1",
          "datamodule.train_data_path=/mnt/rlfh/tldr-openai-filtered/train_remove_hfids.jsonl",
          "datamodule.test_data_path=/mnt/rlfh/tldr-openai-filtered/test.jsonl",
          "datamodule.valid_data_path=/mnt/rlfh/tldr-openai-filtered/valid.jsonl",
          "datamodule.train_hf_data_path=/mnt/rlfh/aligned_hf/train.json",
          "EKSArgs.experiment_name=kaixianl-RLFH",
          "EKSArgs.run_name=sftpv2-hfabs-t5-small",
          "model.OptimizerArgs.seed=3",
          "model.OptimizerArgs.learning_rate=1e-4",
          "model.OptimizerArgs.loss_beta=1",
          "model.OptimizerArgs.hf_sample_ratio=0.5",
          "model.type_hf=random",
          "datamodule.batch_size=8",
          "datamodule.num_workers=0"
          ]
args: [
]