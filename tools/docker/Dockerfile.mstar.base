#syntax=docker/dockerfile:1.2
FROM nvidia/cuda:11.7.1-devel-ubuntu20.04 as base
LABEL maintainer="MStar Team"

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/usr/local/lib" \
    PYTHONIOENCODING=UTF-8 \
    LANG=C.UTF-8 \
    LC_ALL=C.UTF-8 \
    SHELL=/bin/bash

RUN --mount=type=cache,target=/var/cache/apt --mount=type=cache,target=/var/lib/apt \
    export DEBIAN_FRONTEND=noninteractive && \
    apt-get update && \
    apt-get install -y \
        build-essential autoconf libtool cmake ninja-build fuse iproute2 \
        libcudnn8 libcudnn8-dev \
        libzstd-dev wget git unzip python3-dev python3-pip && \
    rm -rf /var/lib/apt/lists/*

# Require ccache>=3.7.9 to cache nvcc outputs
RUN cd /usr/local/src && \
    git clone --recursive https://github.com/ccache/ccache.git && \
    cd ccache && \
    git checkout v4.3 && \
    mkdir build; cd build; cmake -GNinja -DCMAKE_BUILD_TYPE=Release .. && \
    ninja && ninja install && \
    cd /usr/local/src && \
    ln -s /usr/local/bin/ccache /usr/local/bin/nvcc && \
    rm -rf ccache

# EFA Support
ENV LD_LIBRARY_PATH=/usr/local/src/nccl/build/lib:/usr/local/cuda/extras/CUPTI/lib64:/opt/amazon/openmpi/lib:/opt/amazon/efa/lib:/opt/aws-ofi-nccl/install/lib:$LD_LIBRARY_PATH
ENV PATH=/opt/amazon/openmpi/bin/:/opt/amazon/efa/bin:$PATH
RUN --mount=type=cache,target=/var/cache/apt --mount=type=cache,target=/var/lib/apt \
    apt-get update && apt-get install -y nvidia-fabricmanager-470 datacenter-gpu-manager && \
    apt-get purge --allow-change-held-packages -y libnccl2 libnccl-dev && \
    cd /usr/local/src && \
    wget https://efa-installer.amazonaws.com/aws-efa-installer-1.15.2.tar.gz && \
    tar -xf aws-efa-installer-1.15.2.tar.gz && \
    cd aws-efa-installer && \
    ./efa_installer.sh -y -g -d --skip-kmod --skip-limit-conf --no-verify && \
    cd /usr/local/src && rm -rf aws-efa-installer-latest.tar.gz aws-efa-installer && \
    cd /usr/local/src && git clone -b v2.13.4-1 https://github.com/NVIDIA/nccl.git && cd nccl && \
    make -j src.build CUDA_HOME=/usr/local/cuda \
      NVCC_GENCODE="-gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_70,code=sm_70" && \
      make install && \
    git clone -b aws https://github.com/aws/aws-ofi-nccl.git /opt/aws-ofi-nccl && \
    cd /opt/aws-ofi-nccl && \
    # v1.2.0 + EFA -FI_EAGAIN fix + nccl 2.12 fix
    git checkout 06b5390f1dc06a2b598954a3b0dd10fb8398f46e && \
    ./autogen.sh && \
    ./configure --prefix=/opt/aws-ofi-nccl/install \
      --with-libfabric=/opt/amazon/efa/ \
      --with-cuda=/usr/local/cuda \
      --with-nccl=/usr/ \
      --with-mpi=/opt/amazon/openmpi/ && \
    make && make install && \
    rm -rf /var/lib/apt/lists/*


# LD_PRELOAD trick to load binary torch with custom libnccl.so (unsupported)
# ENV LD_PRELOAD=/usr/local/src/nccl/build/lib/libnccl.so
RUN --mount=type=cache,target=/root/.cache/pip --mount=type=cache,target=/root/.ccache  \
    python3 -m pip install awscli pyarrow scikit-build pyyaml typing-extensions numpy regex && \
    cd /usr/local/src/ && \
    # Depends on LD_PRELOAD trick
    # pip3 install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio==0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html
    git clone --recursive -j$(nproc) -b release/1.12-zero https://github.com/leezu/pytorch.git && \
    cd pytorch && \
    TORCH_CUDA_ARCH_LIST="8.0 7.5 7.0" USE_SYSTEM_NCCL=ON BUILD_CAFFE2_OPS=0 BUILD_CAFFE2=0 USE_MPI=0 \
        CUDA_NVCC_EXECUTABLE=/usr/local/bin/nvcc python3 setup.py install && \
    cd /usr/local/src/ && rm -rf pytorch

COPY DeepSpeed-ZeRO-2D.tar.gz /usr/local/src/DeepSpeed-ZeRO-2D.tar.gz

RUN --mount=type=cache,target=/root/.cache/pip --mount=type=cache,target=/root/.ccache  \
    TORCH_CUDA_ARCH_LIST="8.0 7.5 7.0" DS_BUILD_UTILS=1 DS_BUILD_FUSED_LAMB=0 python3 -m pip install /usr/local/src/DeepSpeed-ZeRO-2D.tar.gz --no-build-isolation && \
    rm /usr/local/src/DeepSpeed-ZeRO-2D.tar.gz
